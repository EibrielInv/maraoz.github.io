---
layout: post
title:  "[DRAFT] Why achieving AGI matters"
image: "/img/why-agi/cover.jpg"
draft: true
---
<figure>
  <figcaption style="text-align: left">
  Summary: I explain why building an artificial general intelligence is the most important work we can do today. 
  </figcaption>
</figure>
<img class="cover rounded" src="{{ page.image }}">

[A 2020 survey](https://gcrinstitute.org/papers/055_agi-2020.pdf) identified 72 active AGI research projects spread across 37 countries. This is hardly enough people for the most important project for humanity. In this post I'll explain why attempting AGI is the highest leverage bet we can make as a species.

## What is AGI? (skip if you already know the acronym)

AGI stands for artificial general intelligence. But what does the "General" in AGI mean? Folks have different answers. An AI that can do anything a human can do. An AI that can solve any problem given to them. An AI that can surpass human intelligence. 

I prefer this definition: a computer system that can perform *any* task that a human can, given similar amounts of time. This includes studying if it needs to. This includes physical tasks too. If you can reasonably ask some human to do it, then an AGI should also be able to do it.

## Why should this matter? 

### 1. Narrow AI is not enough
The most common reaction to excitement with the potential of creating AGI is related to the actual or potential advances narrow AI (application-specific artificial intelligence, eg: chess, translation, image classification, medical diagnosis).

I am not denying that narrow AI is amazing, and will continue to be. We can already see the benefits it's bringing us in so many aspects of our lives. But I believe that AGI is orders of magnitude more important.  


Narrow AI is not scalable. It can only do the specific tasks it was designed for. This is fine for certain applications. But if we want AI to help us with the really hard problems we face, we need AI that is more flexible. This is the power of generalization and universality. 

### 2. Nation states will control AGI if we don't  
The second reason is that nation states will create AGI if we don't. They will then be in a position to completely control access to the technology. They have the resources and the motivation to do so. We saw this happen with nuclear weapons.  

For example, let's say a big nation state like China or the US has built AGI capability. Imagine the colossally unfair advantage they would have in matters of strategic analysis and surveillance. They could have thousands of "people" thinking about a problem 24/7, making research, and trying out different solutions. They could train bot agents with different skillsets and knowledge, that can work together to defeat any adversary. These "people" never get tired, never take vacation, never get sick, and never quit. They could use AGI to design and manufacture next-generation robotics to autonomously navigate urban environments in real time. They could send these robots to gather ground intelligence anywhere in the world.  
Once a state achieves AGI, they will completely dominate and control all other states and individuals easily. AGI would give them unprecedented power.   

These are just a few examples of the kinds of gargantuan advantages that would be possible with AGI. The point is, whoever controls AGI will have a huge advantage over everyone else.  

### 3. Building a brighter future
The birth of the first AGI would be a technological singularity of such magnitude, that the world order would change. AGI will help us to solve problems that are currently intractable. Problems like climate change, energy and food production, disease, and poverty. Capitalism and nation states brought us to this huge mess and they won't be able to save us from it. [Only an out-of-system agent can coordinate humanity's efforts](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/). AGI could bring about a new world order that enables us to side-step the global problems we currently face.  



## Summary and Final Words 

Liked what you read? Subscribe!
{% include substack.html %}

### Acknowledgements
Cover photo by <a href="https://www.midjourney.com/">MidJourney</a>
  
### Comments and Discussion
[Discuss on HN (soon)]() — [Discuss on Reddit (soon)]() — [Email a private comment](mailto:naming@maraoz.com)


